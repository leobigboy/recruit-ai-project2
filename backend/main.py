import os
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from openai import OpenAI
import logging
import json
import PyPDF2
import io
from pydantic import BaseModel
from typing import List, Optional, Dict, Any

# =========================================
# Load environment
# =========================================
load_dotenv()
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

if not OPENROUTER_API_KEY:
    raise ValueError("‚ùå Thi·∫øu OpenRouter API key trong file .env")

# ‚úÖ Kh√¥ng log key th·∫≠t ra console
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)
logger.info("üîí OpenRouter API key loaded (·∫©n trong log).")

# Kh·ªüi t·∫°o client OpenRouter an to√†n
client = OpenAI(
    api_key=OPENROUTER_API_KEY,
    base_url="https://openrouter.ai/api/v1",
    default_headers={
        "HTTP-Referer": "http://localhost:5173",
        "X-Title": "Recruit AI CV Parser"
    }
)

app = FastAPI(title="CV Parser API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =========================================
# Pydantic Models
# =========================================
class CVData(BaseModel):
    full_name: str
    email: Optional[str] = None
    phone_number: Optional[str] = None
    address: Optional[str] = None
    university: Optional[str] = None
    education: Optional[str] = None
    experience: Optional[str] = None

class JobData(BaseModel):
    id: str
    title: str
    department: Optional[str] = None
    level: Optional[str] = None
    job_type: Optional[str] = None
    work_location: Optional[str] = None
    location: Optional[str] = None
    description: Optional[str] = None
    requirements: Optional[str] = None
    benefits: Optional[str] = None

class MatchCVJobsRequest(BaseModel):
    cv_text: str
    cv_data: CVData
    jobs: List[JobData]
    primary_job_id: Optional[str] = None

# =========================================
# Helper: ƒê·ªçc PDF
# =========================================
def extract_text_from_pdf(content: bytes) -> str:
    """Tr√≠ch xu·∫•t text t·ª´ PDF bytes"""
    try:
        pdf_file = io.BytesIO(content)
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"

        if text.strip():
            return text

        return content.decode("utf-8", errors="ignore")
    except Exception as e:
        logger.warning(f"L·ªói ƒë·ªçc PDF: {e}, fallback sang UTF-8")
        return content.decode("utf-8", errors="ignore")

# =========================================
# Route ki·ªÉm tra server
# =========================================
@app.get("/health")
def health_check():
    return {"status": "healthy", "model_loaded": True}

# =========================================
# Route parse 1 CV
# =========================================
@app.post("/api/parse-cv")
async def parse_cv(file: UploadFile = File(...)):
    try:
        content = await file.read()

        # ‚úÖ X·ª≠ l√Ω PDF ƒë√∫ng c√°ch
        if file.filename.lower().endswith('.pdf'):
            text = extract_text_from_pdf(content)
        else:
            text = content.decode("utf-8", errors="ignore")

        logger.info(f"üìÑ ƒê·ªçc ƒë∆∞·ª£c {len(text)} k√Ω t·ª± t·ª´ {file.filename}")

        if not text or len(text.strip()) < 50:
            raise HTTPException(status_code=400, detail="File tr·ªëng ho·∫∑c kh√¥ng ƒë·ªçc ƒë∆∞·ª£c n·ªôi dung")

        prompt = f"""
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch CV. H√£y ƒë·ªçc k·ªπ CV sau v√† tr√≠ch xu·∫•t th√¥ng tin CH√çNH X√ÅC.

QUAN TR·ªåNG: 
- N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin, ƒë·ªÉ tr·ªëng "" thay v√¨ "N/A"
- Skills ph·∫£i l√† array c√°c string
- Tr·∫£ v·ªÅ ƒê√öNG ƒë·ªãnh d·∫°ng JSON, kh√¥ng th√™m markdown ```json
- ƒê·∫∂C BI·ªÜT CH√ö √ù: Tr∆∞·ªùng "name" l√† H·ªå T√äN ·ª®NG VI√äN, th∆∞·ªùng ·ªü ƒë·∫ßu CV, l√† T√äN NG∆Ø·ªúI, kh√¥ng ph·∫£i t√™n c√¥ng ty hay t√™n d·ª± √°n

Tr·∫£ v·ªÅ JSON v·ªõi c·∫•u tr√∫c:
{{
  "name": "t√™n ƒë·∫ßy ƒë·ªß c·ªßa ·ª©ng vi√™n",
  "email": "email",
  "phone": "s·ªë ƒëi·ªán tho·∫°i",
  "address": "ƒë·ªãa ch·ªâ",
  "skills": ["skill1", "skill2", "skill3"],
  "experience": "kinh nghi·ªám l√†m vi·ªác",
  "education": "h·ªçc v·∫•n",
  "university": "t√™n tr∆∞·ªùng"
}}

CV Content:
{text[:4000]}
"""

        response = client.chat.completions.create(
            model="openai/gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.1,
        )

        result_text = response.choices[0].message.content.strip()
        logger.info("ü§ñ GPT response nh·∫≠n th√†nh c√¥ng.")

        # Parse JSON
        try:
            if result_text.startswith("```json"):
                result_text = result_text.replace("```json", "").replace("```", "").strip()
            elif result_text.startswith("```"):
                result_text = result_text.replace("```", "").strip()

            parsed_json = json.loads(result_text)
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Cannot parse JSON: {e}")
            logger.error(f"Raw response: {result_text[:500]}")
            parsed_json = {}

        # Chu·∫©n h√≥a d·ªØ li·ªáu
        def safe_get(field, default=""):
            return parsed_json.get(field, default) if parsed_json else default

        name = safe_get("name")
        email = safe_get("email")
        phone = safe_get("phone")
        address = safe_get("address")
        skills = safe_get("skills", [])
        experience = safe_get("experience")
        education = safe_get("education")
        university = safe_get("university")

        if isinstance(skills, str):
            skills = [s.strip() for s in skills.split(",") if s.strip()]

        # ‚úÖ FIX: Truy c·∫≠p usage object ƒë√∫ng c√°ch
        tokens_count = None
        if hasattr(response, 'usage') and response.usage:
            tokens_count = response.usage.total_tokens

        return {
            "success": True,
            "data": {
                "name": name,
                "email": email,
                "phone": phone,
                "address": address,
                "skills": skills,
                "experience": experience,
                "education": education,
                "university": university,
                "fullText": text[:1000],
                "parseQuality": "good",
            },
            "metadata": {
                "tokens_count": tokens_count,
                "confidence": 0.85,
                "model": "openai/gpt-4o"
            }
        }

    except HTTPException as e:
        raise e
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi x·ª≠ l√Ω CV: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω CV: {str(e)}")

# =========================================
# Route match CV v·ªõi Jobs
# =========================================
@app.post("/api/match-cv-jobs")
async def match_cv_jobs(request: MatchCVJobsRequest):
    """
    Ph√¢n t√≠ch ƒë·ªô ph√π h·ª£p c·ªßa CV v·ªõi c√°c Jobs b·∫±ng GPT-4o
    """
    try:
        cv_text = request.cv_text
        cv_data = request.cv_data
        jobs = request.jobs
        primary_job_id = request.primary_job_id

        if not cv_text or not cv_data or not jobs:
            raise HTTPException(status_code=400, detail="Thi·∫øu th√¥ng tin CV ho·∫∑c Jobs")

        logger.info(f"üéØ Analyzing CV matching v·ªõi {len(jobs)} jobs...")

        # Build jobs context
        jobs_context = ""
        primary_job = None
        
        for job in jobs:
            is_primary = job.id == primary_job_id
            if is_primary:
                primary_job = job
            
            jobs_context += f"""{'‚≠ê PRIMARY JOB - ' if is_primary else ''}Job {job.id}:
- Ti√™u ƒë·ªÅ: {job.title}
- Ph√≤ng ban: {job.department or 'N/A'}
- C·∫•p ƒë·ªô: {job.level or 'N/A'}
- Lo·∫°i h√¨nh: {job.job_type or 'N/A'}
- ƒê·ªãa ƒëi·ªÉm l√†m vi·ªác: {job.work_location or job.location or 'N/A'}
- M√¥ t·∫£ c√¥ng vi·ªác: {job.description or 'N/A'}
- Y√™u c·∫ßu c√¥ng vi·ªác: {job.requirements or 'N/A'}
- Quy·ªÅn l·ª£i: {job.benefits or 'N/A'}
{'(ƒê√¢y l√† v·ªã tr√≠ ·ª©ng vi√™n ƒë√£ apply - ∆∞u ti√™n ƒë√°nh gi√°)' if is_primary else ''}

"""

        # Build CV context
        cv_context = f"""
CV c·ªßa ·ª©ng vi√™n:
- H·ªç v√† t√™n: {cv_data.full_name}
- Email: {cv_data.email or 'N/A'}
- S·ªë ƒëi·ªán tho·∫°i: {cv_data.phone_number or 'N/A'}
- ƒê·ªãa ch·ªâ: {cv_data.address or 'N/A'}
- Tr∆∞·ªùng ƒë·∫°i h·ªçc: {cv_data.university or 'N/A'}
- H·ªçc v·∫•n: {cv_data.education or 'N/A'}
- Kinh nghi·ªám l√†m vi·ªác: {cv_data.experience or 'N/A'}
- N·ªôi dung chi ti·∫øt CV: {cv_text[:3000]}
"""

        primary_job_title = primary_job.title if primary_job else ""

        prompt = f"""B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng HR chuy√™n nghi·ªáp trong lƒ©nh v·ª±c IT v·ªõi h∆°n 15 nƒÉm kinh nghi·ªám. H√£y ph√¢n t√≠ch CV sau so v·ªõi c√°c Job v·ªã tr√≠ ·ª©ng tuy·ªÉn t∆∞∆°ng ·ª©ng v√† ƒë√°nh gi√° ƒë·ªô ph√π h·ª£p v·ªõi c√°c c√¥ng vi·ªác m·ªôt c√°ch CHI TI·∫æT v√† CH√çNH X√ÅC.

{cv_context}

C√ÅC C√îNG VI·ªÜC C·∫¶N ƒê√ÅNH GI√Å:
{jobs_context}

H∆Ø·ªöNG D·∫™N ƒê√ÅNH GI√Å:
1. ƒê√°nh gi√° theo c√°c ti√™u ch√≠ sau (thang ƒëi·ªÉm 100):
   - Kinh nghi·ªám li√™n quan (30 ƒëi·ªÉm): So s√°nh kinh nghi·ªám v·ªõi y√™u c·∫ßu c√¥ng vi·ªác
   - K·ªπ nƒÉng k·ªπ thu·∫≠t (25 ƒëi·ªÉm): ƒê√°nh gi√° k·ªπ nƒÉng chuy√™n m√¥n ph√π h·ª£p
   - H·ªçc v·∫•n (15 ƒëi·ªÉm): B·∫±ng c·∫•p, tr∆∞·ªùng h·ªçc ph√π h·ª£p v·ªõi y√™u c·∫ßu
   - C·∫•p ƒë·ªô ph√π h·ª£p (15 ƒëi·ªÉm): Level (Junior/Mid/Senior) kh·ªõp v·ªõi y√™u c·∫ßu
   - ƒê·ªãa ƒëi·ªÉm (10 ƒëi·ªÉm): Ph√π h·ª£p v·ªõi work_location
   - Soft skills (5 ƒëi·ªÉm): K·ªπ nƒÉng m·ªÅm t·ª´ CV

2. {f'∆ØU TI√äN ƒë√°nh gi√° cho Job "{primary_job_title}" (c√≥ d·∫•u ‚≠ê) v√¨ ƒë√¢y l√† v·ªã tr√≠ ·ª©ng vi√™n ƒë√£ apply.' if primary_job else 'ƒê√°nh gi√° c√¥ng b·∫±ng cho t·∫•t c·∫£ c√°c jobs.'}

3. Ph√¢n t√≠ch C·ª§ TH·ªÇ:
   - ƒêi·ªÉm m·∫°nh: Li·ªát k√™ c√°c ƒëi·ªÉm ph√π h·ª£p C·ª§ TH·ªÇ v·ªõi t·ª´ng job (t·ªëi thi·ªÉu 3 ƒëi·ªÉm)
   - ƒêi·ªÉm y·∫øu: Ch·ªâ ra thi·∫øu s√≥t ho·∫∑c kh√¥ng ph√π h·ª£p (1-2 ƒëi·ªÉm)
   - Khuy·∫øn ngh·ªã: ƒê∆∞a ra l·ªùi khuy√™n CHI TI·∫æT (50-100 t·ª´)

4. Ch·∫•m ƒëi·ªÉm TH·ª∞C T·∫æ v√† CH√çNH X√ÅC:
   - Tr√°nh ch·∫•m ƒëi·ªÉm qu√° cao n·∫øu kh√¥ng ƒë·ªß ƒëi·ªÅu ki·ªán
   - Tr√°nh ch·∫•m ƒëi·ªÉm qu√° th·∫•p n·∫øu ·ª©ng vi√™n c√≥ ti·ªÅm nƒÉng
   - Gi·∫£i th√≠ch r√µ r√†ng t·∫°i sao cho ƒëi·ªÉm ƒë√≥

H√ÉY TR·∫¢ V·ªÄ JSON v·ªõi format SAU (CH√çNH X√ÅC, kh√¥ng th√™m text n√†o kh√°c):
{{
  "overall_score": 85,
  "best_match": {{
    "job_id": "job-uuid-here",
    "job_title": "Job Title",
    "match_score": 92,
    "strengths": ["C√≥ X nƒÉm kinh nghi·ªám v·ªõi c√¥ng ngh·ªá Y ph√π h·ª£p v·ªõi y√™u c·∫ßu", "H·ªçc v·∫•n ƒë·∫°t chu·∫©n v·ªõi b·∫±ng Z t·ª´ tr∆∞·ªùng A", "K·ªπ nƒÉng B,C,D match v·ªõi requirements"],
    "weaknesses": ["Thi·∫øu kinh nghi·ªám v·ªÅ aspect X ƒë∆∞·ª£c n√™u trong JD", "Ch∆∞a l√†m vi·ªác v·ªõi tool Y"],
    "recommendation": "·ª®ng vi√™n c√≥ n·ªÅn t·∫£ng v·ªØng ch·∫Øc v√† kinh nghi·ªám ph√π h·ª£p. ƒêi·ªÉm m·∫°nh n·ªïi b·∫≠t l√†... Tuy nhi√™n c·∫ßn b·ªï sung th√™m v·ªÅ... N√™n m·ªùi ph·ªèng v·∫•n ƒë·ªÉ ƒë√°nh gi√° s√¢u h∆°n v·ªÅ..."
  }},
  "all_matches": [
    {{
      "job_id": "job-uuid-1",
      "job_title": "Job 1",
      "match_score": 92,
      "strengths": ["Strength 1 c·ª• th·ªÉ", "Strength 2 c·ª• th·ªÉ", "Strength 3 c·ª• th·ªÉ"],
      "weaknesses": ["Weakness 1 c·ª• th·ªÉ", "Weakness 2 c·ª• th·ªÉ"],
      "recommendation": "Khuy·∫øn ngh·ªã chi ti·∫øt v√† c·ª• th·ªÉ"
    }}
  ]
}}

L∆ØU √ù QUAN TR·ªåNG:
- overall_score: ƒêi·ªÉm T·ªîNG TH·ªÇ d·ª±a tr√™n best_match (0-100)
- match_score: ƒêi·ªÉm ph√π h·ª£p cho T·ª™NG job (0-100)
- best_match: C√¥ng vi·ªác ph√π h·ª£p NH·∫§T {f'(∆∞u ti√™n "{primary_job_title}")' if primary_job else ''}
- S·∫Øp x·∫øp all_matches theo match_score GI·∫¢M D·∫¶N
- PH·∫¢I c√≥ √≠t nh·∫•t 3 strengths v√† 1-2 weaknesses cho m·ªói job
- recommendation PH·∫¢I chi ti·∫øt, c·ª• th·ªÉ, t·ª´ 50-100 t·ª´
"""

        # Call OpenRouter API
        response = client.chat.completions.create(
            model="openai/gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": "B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng HR chuy√™n nghi·ªáp trong lƒ©nh v·ª±c IT v·ªõi h∆°n 15 nƒÉm kinh nghi·ªám. H√£y ph√¢n t√≠ch CV so v·ªõi c√°c Job v√† ƒë√°nh gi√° ƒë·ªô ph√π h·ª£p m·ªôt c√°ch CHI TI·∫æT v√† CH√çNH X√ÅC. Tr·∫£ v·ªÅ JSON ƒë√∫ng format ƒë∆∞·ª£c y√™u c·∫ßu."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=2500,
            temperature=0.2,
        )

        result_text = response.choices[0].message.content.strip()
        logger.info("ü§ñ GPT matching analysis th√†nh c√¥ng.")

        # Parse JSON
        try:
            if result_text.startswith("```json"):
                result_text = result_text.replace("```json", "").replace("```", "").strip()
            elif result_text.startswith("```"):
                result_text = result_text.replace("```", "").strip()

            analysis_result = json.loads(result_text)
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Cannot parse JSON: {e}")
            logger.error(f"Raw response: {result_text[:500]}")
            raise HTTPException(status_code=500, detail="AI tr·∫£ v·ªÅ d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá")

        # Get tokens count
        tokens_count = None
        if hasattr(response, 'usage') and response.usage:
            tokens_count = response.usage.total_tokens

        return {
            "success": True,
            "data": analysis_result,
            "metadata": {
                "tokens_count": tokens_count,
                "jobs_analyzed": len(jobs),
                "model": "openai/gpt-4o"
            }
        }

    except HTTPException as e:
        raise e
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi match CV v·ªõi jobs: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"L·ªói ph√¢n t√≠ch: {str(e)}")

# =========================================
# Route parse nhi·ªÅu CV
# =========================================
@app.post("/api/batch-parse-cv")
async def batch_parse_cv(files: list[UploadFile]):
    results = []
    for file in files:
        try:
            parsed = await parse_cv(file)
            results.append({
                "filename": file.filename,
                "success": True,
                "data": parsed["data"]
            })
        except Exception as e:
            results.append({
                "filename": file.filename,
                "success": False,
                "error": str(e)
            })
    return {"results": results}

# =========================================
# Ch·∫°y server
# =========================================
if __name__ == "__main__":
    import uvicorn
    logger.info("‚úÖ OpenRouter client kh·ªüi t·∫°o an to√†n.")
    logger.info("üöÄ Backend API ƒëang ch·∫°y tr√™n http://0.0.0.0:8000")
    logger.info("üìù Endpoints:")
    logger.info("   - GET  /health")
    logger.info("   - POST /api/parse-cv")
    logger.info("   - POST /api/match-cv-jobs")
    logger.info("   - POST /api/batch-parse-cv")
    uvicorn.run(app, host="0.0.0.0", port=8000)